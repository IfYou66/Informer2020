{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:45.356324Z",
     "start_time": "2025-03-05T08:00:44.342948Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#忽略所有warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:46.177461Z",
     "start_time": "2025-03-05T08:00:45.365329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载所有数据\n",
    "train = pd.read_csv('./store-sales-time-series-forecasting/train.csv',  parse_dates=['date'])\n",
    "test = pd.read_csv('./store-sales-time-series-forecasting/test.csv',  parse_dates=['date'])\n",
    "stores = pd.read_csv('./store-sales-time-series-forecasting/stores.csv')\n",
    "oil = pd.read_csv('./store-sales-time-series-forecasting/oil.csv',  parse_dates=['date'])\n",
    "holidays = pd.read_csv('./store-sales-time-series-forecasting/holidays_events.csv',  parse_dates=['date'])"
   ],
   "id": "8b1c25262efb6bd8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:46.287339Z",
     "start_time": "2025-03-05T08:00:46.241626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. 转换日期格式（确保所有数据中日期字段为 datetime 格式）\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "oil['date'] = pd.to_datetime(oil['date'])\n",
    "holidays['date'] = pd.to_datetime(holidays['date'])"
   ],
   "id": "d6c7ff14c50f8a5e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:46.299622Z",
     "start_time": "2025-03-05T08:00:46.296323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 打印数据集大小\n",
    "print(\"Train dataset size:\", train.shape)"
   ],
   "id": "2863ec704949ae6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: (3000888, 6)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:46.323516Z",
     "start_time": "2025-03-05T08:00:46.319452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. 处理 holidays_events 数据\n",
    "# 根据说明：Transferred 类型视作正常日，其它假日类型认为是假日\n",
    "holidays['is_holiday'] = holidays['type'].apply(lambda x: 0 if x == 'Transfer' else 1)\n",
    "# 如果一天内有多个事件，则取最大值（即只要有非 Transfer 的事件，该天就视作假日）\n",
    "holidays_daily = holidays.groupby('date')['is_holiday'].max().reset_index()\n"
   ],
   "id": "78f16e754d84767e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:46.401067Z",
     "start_time": "2025-03-05T08:00:46.326521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. 合并外部数据\n",
    "# 4.1 合并油价数据：按日期合并到训练集和测试集（左连接保证保留所有主数据的日期）\n",
    "train = pd.merge(train, oil[['date', 'dcoilwtico']], on='date', how='left')\n",
    "test = pd.merge(test, oil[['date', 'dcoilwtico']], on='date', how='left')\n"
   ],
   "id": "6fa2091ac8e58711",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:46.610077Z",
     "start_time": "2025-03-05T08:00:46.412187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4.2 合并商店数据：按 store_nbr 合并\n",
    "train = pd.merge(train, stores, on='store_nbr', how='left')\n",
    "test = pd.merge(test, stores, on='store_nbr', how='left')"
   ],
   "id": "f39b9e060f745062",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:46.862605Z",
     "start_time": "2025-03-05T08:00:46.623511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4.3 合并 holidays 数据：按日期合并\n",
    "train = pd.merge(train, holidays_daily, on='date', how='left')\n",
    "test = pd.merge(test, holidays_daily, on='date', how='left')\n",
    "# 对于没有合并到的日期，填充 is_holiday = 0\n",
    "train['is_holiday'] = train['is_holiday'].fillna(0)\n",
    "test['is_holiday'] = test['is_holiday'].fillna(0)"
   ],
   "id": "ccbe07444f0ab4d6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:46.877023Z",
     "start_time": "2025-03-05T08:00:46.873018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. 生成日期特征\n",
    "def add_date_features(df):\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['weekday'] = df['date'].dt.weekday  # Monday=0, Sunday=6\n",
    "    # 发薪日：每月15日和每月最后一天\n",
    "    df['is_payday'] = df['date'].apply(lambda x: 1 if (x.day == 15 or x.day == calendar.monthrange(x.year, x.month)[1]) else 0)\n",
    "    return df"
   ],
   "id": "e5836b427d38f93b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:50.249064Z",
     "start_time": "2025-03-05T08:00:46.888807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = add_date_features(train)\n",
    "test = add_date_features(test)"
   ],
   "id": "d45dd4cdb7dd6bb9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:50.265017Z",
     "start_time": "2025-03-05T08:00:50.260877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 6. 生成特殊事件特征：针对2016-04-16地震\n",
    "# 例如：假设地震对4月16日至5月底的销售产生影响，这里创建一个标记\n",
    "def add_earthquake_feature(df):\n",
    "    # 根据需要调整时间窗口\n",
    "    earthquake_start = pd.to_datetime('2016-04-16')\n",
    "    earthquake_end = pd.to_datetime('2016-05-31')\n",
    "    df['is_earthquake_period'] = df['date'].apply(lambda x: 1 if earthquake_start <= x <= earthquake_end else 0)\n",
    "    return df"
   ],
   "id": "b55273752c847b98",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:52.450807Z",
     "start_time": "2025-03-05T08:00:50.276648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = add_earthquake_feature(train)\n",
    "test = add_earthquake_feature(test)"
   ],
   "id": "c4f3b6e0d1f99d80",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:52.676233Z",
     "start_time": "2025-03-05T08:00:52.465192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 7. 检查缺失值情况（这里只是简单地打印各个数据集的缺失情况）\n",
    "print(\"Train missing values:\")\n",
    "print(train.isnull().sum())\n",
    "print(\"\\nTest missing values:\")\n",
    "print(test.isnull().sum())"
   ],
   "id": "d601f13bca5c0914",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train missing values:\n",
      "id                           0\n",
      "date                         0\n",
      "store_nbr                    0\n",
      "family                       0\n",
      "sales                        0\n",
      "onpromotion                  0\n",
      "dcoilwtico              928422\n",
      "city                         0\n",
      "state                        0\n",
      "type                         0\n",
      "cluster                      0\n",
      "is_holiday                   0\n",
      "year                         0\n",
      "month                        0\n",
      "day                          0\n",
      "weekday                      0\n",
      "is_payday                    0\n",
      "is_earthquake_period         0\n",
      "dtype: int64\n",
      "\n",
      "Test missing values:\n",
      "id                         0\n",
      "date                       0\n",
      "store_nbr                  0\n",
      "family                     0\n",
      "onpromotion                0\n",
      "dcoilwtico              7128\n",
      "city                       0\n",
      "state                      0\n",
      "type                       0\n",
      "cluster                    0\n",
      "is_holiday                 0\n",
      "year                       0\n",
      "month                      0\n",
      "day                        0\n",
      "weekday                    0\n",
      "is_payday                  0\n",
      "is_earthquake_period       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:52.697894Z",
     "start_time": "2025-03-05T08:00:52.689152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 8. 检查油价相关的重复列（可选）\n",
    "print(\"油价相关的前几行数据：\")\n",
    "print(train[['dcoilwtico']].head())"
   ],
   "id": "9b1d8e529e5a2274",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "油价相关的前几行数据：\n",
      "   dcoilwtico\n",
      "0         NaN\n",
      "1         NaN\n",
      "2         NaN\n",
      "3         NaN\n",
      "4         NaN\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:52.713768Z",
     "start_time": "2025-03-05T08:00:52.710684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 9. 删除重复的油价列，只保留 dcoilwtico 这一列\n",
    "# train = train.drop(['dcoilwtico_x', 'dcoilwtico_y'], axis=1)\n",
    "# test = test.drop(['dcoilwtico_x', 'dcoilwtico_y'], axis=1)"
   ],
   "id": "5ce7eb7a2e41fa8b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:52.749800Z",
     "start_time": "2025-03-05T08:00:52.725515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 10. 对 dcoilwtico 列进行缺失值填充\n",
    "# 先用前向填充，再用后向填充（以防数据开头处仍有缺失）\n",
    "train['dcoilwtico'] = train['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n",
    "test['dcoilwtico'] = test['dcoilwtico'].fillna(method='ffill').fillna(method='bfill')\n"
   ],
   "id": "3fa94e4c71eeb843",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:52.970526Z",
     "start_time": "2025-03-05T08:00:52.763012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 11. 检查处理后的缺失值情况\n",
    "print(\"处理后的Train缺失值情况：\")\n",
    "print(train.isnull().sum())\n",
    "print(\"\\n处理后的Test缺失值情况：\")\n",
    "print(test.isnull().sum())"
   ],
   "id": "494736b46f435013",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理后的Train缺失值情况：\n",
      "id                      0\n",
      "date                    0\n",
      "store_nbr               0\n",
      "family                  0\n",
      "sales                   0\n",
      "onpromotion             0\n",
      "dcoilwtico              0\n",
      "city                    0\n",
      "state                   0\n",
      "type                    0\n",
      "cluster                 0\n",
      "is_holiday              0\n",
      "year                    0\n",
      "month                   0\n",
      "day                     0\n",
      "weekday                 0\n",
      "is_payday               0\n",
      "is_earthquake_period    0\n",
      "dtype: int64\n",
      "\n",
      "处理后的Test缺失值情况：\n",
      "id                      0\n",
      "date                    0\n",
      "store_nbr               0\n",
      "family                  0\n",
      "onpromotion             0\n",
      "dcoilwtico              0\n",
      "city                    0\n",
      "state                   0\n",
      "type                    0\n",
      "cluster                 0\n",
      "is_holiday              0\n",
      "year                    0\n",
      "month                   0\n",
      "day                     0\n",
      "weekday                 0\n",
      "is_payday               0\n",
      "is_earthquake_period    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:00:54.019360Z",
     "start_time": "2025-03-05T08:00:53.029572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 对字符串特征进行标签编码\n",
    "# 需要编码的列：family、city、state、type\n",
    "# 注意：为保证训练和测试中编码一致，先在训练集上 fit，再 transform 测试集\n",
    "for col in ['family', 'city', 'state', 'type']:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col].astype(str))\n",
    "    test[col] = le.transform(test[col].astype(str))"
   ],
   "id": "e23b33d487a408f7",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:01:38.745953Z",
     "start_time": "2025-03-05T08:01:38.741073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 查看处理结果\n",
    "print(\"处理后的Train前几行：\")\n",
    "print(train.head())\n",
    "print(\"Train dataset size:\", train.shape)"
   ],
   "id": "d99df375d27a0085",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理后的Train前几行：\n",
      "   id       date  store_nbr  family  sales  onpromotion  dcoilwtico  city  \\\n",
      "0   0 2013-01-01          1       0    0.0            0       93.14    18   \n",
      "1   1 2013-01-01          1       1    0.0            0       93.14    18   \n",
      "2   2 2013-01-01          1       2    0.0            0       93.14    18   \n",
      "3   3 2013-01-01          1       3    0.0            0       93.14    18   \n",
      "4   4 2013-01-01          1       4    0.0            0       93.14    18   \n",
      "\n",
      "   state  type  cluster  is_holiday  year  month  day  weekday  is_payday  \\\n",
      "0     12     3       13         1.0  2013      1    1        1          0   \n",
      "1     12     3       13         1.0  2013      1    1        1          0   \n",
      "2     12     3       13         1.0  2013      1    1        1          0   \n",
      "3     12     3       13         1.0  2013      1    1        1          0   \n",
      "4     12     3       13         1.0  2013      1    1        1          0   \n",
      "\n",
      "   is_earthquake_period  \n",
      "0                     0  \n",
      "1                     0  \n",
      "2                     0  \n",
      "3                     0  \n",
      "4                     0  \n",
      "Train dataset size: (3000888, 18)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:01:02.459002Z",
     "start_time": "2025-03-05T08:00:54.112821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 12. 保存预处理后的数据（根据需要进行保存）\n",
    "train.to_csv('./favourite/train_preprocessed.csv', index=False)\n",
    "test.to_csv('./favourite/test_preprocessed.csv', index=False)\n",
    "\n",
    "print(\"数据预处理完成，预处理后的数据已保存。\")"
   ],
   "id": "fb0f4d67e35c98db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据预处理完成，预处理后的数据已保存。\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T08:02:47.334630Z",
     "start_time": "2025-03-05T08:02:45.884527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#将train_preprocessed.csv的前5行保存到train.csv中\n",
    "train = pd.read_csv('./favourite/train_preprocessed.csv')\n",
    "train.head().to_csv('./favourite/train.csv', index=False)"
   ],
   "id": "1fab3320611e74f8",
   "outputs": [],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
